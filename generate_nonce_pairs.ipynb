{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashim/indicmt/env_mt/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3044: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'sentID', 'wordPosition', 'word', 'lemma', 'UPOS', 'XPOS',\n",
       "       'FEATS', 'HEAD', 'DEPREL', 'DEPS', 'MISC', 'category', 'gender',\n",
       "       'number', 'person', 'case', 'vib', 'tam'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Read dataframe\n",
    "malConll = pd.read_csv('malExpanded.conllu')\n",
    "# del malConll['Unnamed: 0']\n",
    "malConll['word'] = malConll['word'].astype(str)\n",
    "malConll['lemma'] = malConll['lemma'].astype(str)\n",
    "malConll['DEPS'] = malConll['DEPS'].astype(str)\n",
    "type(malConll['word'].iloc[0])\n",
    "malConll.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentID_group_obj = malConll.groupby('sentID')\n",
    "sent_ids = list(sentID_group_obj.groups.keys())\n",
    "g1 = sentID_group_obj.groups['malayalam/final data - validated/03-06-2017/agriculture/Depn/cross_breeding_of_coconut_trees.depn.ssf:1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'sentID', 'wordPosition', 'word', 'lemma', 'UPOS', 'XPOS',\n",
       "       'FEATS', 'HEAD', 'DEPREL', 'DEPS', 'MISC', 'category', 'gender',\n",
       "       'number', 'person', 'case', 'vib', 'tam'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malConll[malConll.index.isin(g1)].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"''\", 'ROOT')\n",
      "101924    ''\n",
      "Name: lemma, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashim/indicmt/env_mt/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43961    43961\n",
       "Name: Unnamed: 0, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "pd.options.display.max_colwidth = 100\n",
    "vibs_dep_group = malConll.groupby(['vib', 'DEPS'])\n",
    "for key, item in vibs_dep_group:\n",
    "    print(key)\n",
    "    print(vibs_dep_group.get_group(key)['lemma'])\n",
    "    break\n",
    "# type(vibs_dep_group.groups.keys())\n",
    "# pd.unique(vibs_dep_group.get_group((\"ഉ്\", 'k4'))['lemma'])\n",
    "type(vibs_dep_group.get_group((\"ഉ്\", 'k4')))\n",
    "vibs_dep_group_df = vibs_dep_group.get_group((\"ഉ്\", 'k4'))\n",
    "type(vibs_dep_group_df[~vibs_dep_group_df['lemma'].isin(['ഗംഗാസ്നാന'])])\n",
    "df_test = vibs_dep_group_df[~vibs_dep_group_df['lemma'].isin(['ഗംഗാസ്നാന'])]\n",
    "df_test.ix[np.random.choice(df_test.index, 1)]['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding possible replacements for words...\n",
      "Sentence IDs Done 0/13370\n",
      "Sentence IDs Done 1000/13370\n",
      "Sentence IDs Done 2000/13370\n",
      "Sentence IDs Done 3000/13370\n",
      "Sentence IDs Done 4000/13370\n",
      "Sentence IDs Done 5000/13370\n",
      "Sentence IDs Done 6000/13370\n",
      "Sentence IDs Done 7000/13370\n",
      "Sentence IDs Done 8000/13370\n",
      "Sentence IDs Done 9000/13370\n",
      "Sentence IDs Done 10000/13370\n",
      "Sentence IDs Done 11000/13370\n",
      "Sentence IDs Done 12000/13370\n",
      "Sentence IDs Done 13000/13370\n",
      "61034\n",
      "Finding sentences that don't have any possible nonce sentence...\n",
      "Sentence IDs Done 0/13370\n",
      "Sentence IDs Done 1000/13370\n",
      "Sentence IDs Done 2000/13370\n",
      "Sentence IDs Done 3000/13370\n",
      "Sentence IDs Done 4000/13370\n",
      "Sentence IDs Done 5000/13370\n",
      "Sentence IDs Done 6000/13370\n",
      "Sentence IDs Done 7000/13370\n",
      "Sentence IDs Done 8000/13370\n",
      "Sentence IDs Done 9000/13370\n",
      "Sentence IDs Done 10000/13370\n",
      "Sentence IDs Done 11000/13370\n",
      "Sentence IDs Done 12000/13370\n",
      "Sentence IDs Done 13000/13370\n",
      "Total Sentence IDs : 13370\n",
      "To be skipped : 13367\n"
     ]
    }
   ],
   "source": [
    "# Group by Object on vib and DEPS\n",
    "vibs_dep_group = malConll.groupby(['vib', 'DEPS'])\n",
    "vibs_dep_group_keys = vibs_dep_group.groups.keys()\n",
    "\n",
    "word_index_to_df = {}\n",
    "index_none = set()\n",
    "\n",
    "print(\"Finding possible replacements for words...\")\n",
    "# Get Nonce and corresponding incorrect sentences\n",
    "def get_possible_replacements(row):\n",
    "\n",
    "    if pd.isnull(row['vib']) or pd.isnull(row['DEPS']):\n",
    "        return None\n",
    "    \n",
    "    key_to_match = (row['vib'], row['DEPS'])\n",
    "    # Can Not find nonce if for a word there's no other lemma with same vib, DEPS\n",
    "    if key_to_match not in vibs_dep_group_keys:\n",
    "        return None            \n",
    "    # Dataframe\n",
    "    same_vib_deps_group = vibs_dep_group.get_group(key_to_match)\n",
    "    # Dataframe (Same vib and DEPS - Different lemma)\n",
    "    possible_replacements = same_vib_deps_group[~same_vib_deps_group['lemma'].isin([row['lemma']])]\n",
    "    \n",
    "    return possible_replacements\n",
    "\n",
    "for i, sid in enumerate(sent_ids):\n",
    "    \n",
    "    if i %1000 == 0:\n",
    "        print(\"Sentence IDs Done {0}/{1}\".format(i, len(sent_ids)))\n",
    "    \n",
    "    # Indices to words for each sentence (type: Int64Index([]))\n",
    "    sentence_index = sentID_group_obj.groups[sid]\n",
    "    sentence_df = malConll[malConll.index.isin(sentence_index)]\n",
    "    \n",
    "    for index, row in sentence_df.iterrows():\n",
    "        ret_value = get_possible_replacements(row)\n",
    "        if ret_value is None:\n",
    "            index_none.add(index)\n",
    "        elif ret_value.empty:\n",
    "            index_none.add(index)\n",
    "            ret_value = None\n",
    "        word_index_to_df[index] = ret_value\n",
    "\n",
    "# row['DEPS'].startswith('k')\n",
    "print(len(index_none))\n",
    "\n",
    "print(\"Finding sentences that don't have any possible nonce sentence...\")\n",
    "skip_sent_ids = set()\n",
    "for i, sid in enumerate(sent_ids):\n",
    "    \n",
    "    if i %1000 == 0:\n",
    "        print(\"Sentence IDs Done {0}/{1}\".format(i, len(sent_ids)))\n",
    "    \n",
    "    # Indices to words for each sentence (type: Int64Index([]))\n",
    "    sentence_index = sentID_group_obj.groups[sid]\n",
    "    sentence_df = malConll[malConll.index.isin(sentence_index)]\n",
    "    \n",
    "    for index, row in sentence_df.iterrows():\n",
    "        if index in index_none:\n",
    "            skip_sent_ids.add(sid)\n",
    "\n",
    "print(\"Total Sentence IDs : {0}\".format(len(sent_ids)))\n",
    "print(\"To be skipped : {0}\".format(len(skip_sent_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence IDs Done 0/13370\n",
      "Sentence IDs Done 1000/13370\n",
      "Sentence IDs Done 2000/13370\n",
      "Sentence IDs Done 3000/13370\n",
      "Sentence IDs Done 4000/13370\n",
      "Sentence IDs Done 5000/13370\n",
      "Sentence IDs Done 6000/13370\n",
      "Sentence IDs Done 7000/13370\n",
      "Sentence IDs Done 8000/13370\n",
      "Sentence IDs Done 9000/13370\n",
      "Sentence IDs Done 10000/13370\n",
      "Sentence IDs Done 11000/13370\n",
      "Sentence IDs Done 12000/13370\n",
      "Sentence IDs Done 13000/13370\n",
      "121465\n"
     ]
    }
   ],
   "source": [
    "# Group by Object on vib and DEPS\n",
    "deps_lemma_group = malConll.groupby(['DEPS', 'lemma'])\n",
    "deps_lemma_group_keys = deps_lemma_group.groups.keys()\n",
    "\n",
    "word_index_to_df_nonce = word_index_to_df\n",
    "word_index_to_df_incorrect = {}\n",
    "index_incorrect_none = set()\n",
    "\n",
    "\n",
    "def get_possible_incorrects(row):\n",
    "\n",
    "    if pd.isnull(row['vib']) or pd.isnull(row['DEPS']):\n",
    "        return None\n",
    "    \n",
    "    if not row['DEPS'].startswith('k'):\n",
    "        return None\n",
    "    \n",
    "    key_to_match = (row['DEPS'], row['lemma'])\n",
    "    # Can Not find nonce if for a word there's no other lemma with same vib, DEPS\n",
    "    if key_to_match not in deps_lemma_group_keys:\n",
    "        return None\n",
    "    \n",
    "    same_deps_lemma_group = deps_lemma_group.get_group(key_to_match)\n",
    "    possible_incorrects = same_deps_lemma_group[~same_deps_lemma_group['vib'].isin([row['vib']])]\n",
    "    return possible_incorrects\n",
    "\n",
    "for i, sid in enumerate(sent_ids):\n",
    "    \n",
    "    if i %1000 == 0:\n",
    "        print(\"Sentence IDs Done {0}/{1}\".format(i, len(sent_ids)))\n",
    "    \n",
    "    # Indices to words for each sentence (type: Int64Index([]))\n",
    "    sentence_index = sentID_group_obj.groups[sid]\n",
    "    sentence_df = malConll[malConll.index.isin(sentence_index)]\n",
    "    \n",
    "    for index, row in sentence_df.iterrows():\n",
    "        ret_value = get_possible_incorrects(row)\n",
    "        if ret_value is None:\n",
    "            index_incorrect_none.add(index)\n",
    "        elif ret_value.empty:\n",
    "            index_incorrect_none.add(index)\n",
    "            ret_value = None\n",
    "        word_index_to_df_incorrect[index] = ret_value\n",
    "    \n",
    "print(len(index_incorrect_none))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132834\n",
      "malayalam/final data - validated/11-05-2017/tourism (parallel)/Depn/Mal_tourism 1.depn.ssf:125 : [4715, 27569, 111714, 88097]\n",
      "        Unnamed: 0  \\\n",
      "4715          4715   \n",
      "27569        27569   \n",
      "88097        88097   \n",
      "111714      111714   \n",
      "\n",
      "                                                                                                sentID  \\\n",
      "4715           malayalam/full data as on 25-01-2017/not validated/health/depn/MalText83_19.depn.ssf:91   \n",
      "27569      malayalam/full data as on 25-01-2017/not validated/agriculture/depn/MalText74_7.depn.ssf:28   \n",
      "88097                   malayalam/final data - validated/15-07-2017/tourism/Depn/MalText42.depn.ssf:98   \n",
      "111714  malayalam/icon 2016/folder 1 - validated/13dec2016 - batch1/Dependency/MalText53_7.depn.ssf:31   \n",
      "\n",
      "        wordPosition         word  lemma     UPOS XPOS  \\\n",
      "4715               4         അളവു   അളവ്     N_NN    _   \n",
      "27569              2  കേരളത്തില്‍   കേരള   N__NNP    _   \n",
      "88097              3        എത്തി  എത്ത്  V_VM_VF    _   \n",
      "111714             5        തീറ്റ  തീര്ര     N_NN    _   \n",
      "\n",
      "                                                                   FEATS  \\\n",
      "4715          category=n|gender=ne|number=sg|person=3|case=d|vib=0|tam=0   \n",
      "27569   category=n|gender=ne|number=sg|person=3|case=d|vib=ഇല്‍|tam=ttil   \n",
      "88097               category=v|gender=|number=|person=|case=|vib=ഇ|tam=i   \n",
      "111714        category=n|gender=ne|number=sg|person=3|case=d|vib=0|tam=0   \n",
      "\n",
      "        HEAD    DEPREL  DEPS               MISC category gender number person  \\\n",
      "4715       5  k1:VGNF2    k1  id=4.1--chunkID=4        n     ne     sg      3   \n",
      "27569      5   k7p:VGF   k7p  id=2.1--chunkID=2        n     ne     sg      3   \n",
      "88097      0      ROOT  ROOT  id=3.1--chunkID=3        v    NaN    NaN    NaN   \n",
      "111714     6    k2:VGF    k2  id=5.1--chunkID=5        n     ne     sg      3   \n",
      "\n",
      "       case   vib   tam  \n",
      "4715      d     0     0  \n",
      "27569     d  ഇല്‍  ttil  \n",
      "88097   NaN     ഇ     i  \n",
      "111714    d     0     0  \n"
     ]
    }
   ],
   "source": [
    "print(len(word_index_to_df))\n",
    "required_deps = ['k1', 'k2', 'k3', 'k4', 'k5', 'k6', 'k7']\n",
    "\n",
    "sentences_dict = {}\n",
    "\n",
    "traversed = {}\n",
    "\n",
    "\n",
    "def get_new_nonce_sentence(sid):\n",
    "    if sid not in traversed:\n",
    "        traversed[sid] = set()\n",
    "#     if sid in skip_sent_ids:\n",
    "#         continue\n",
    "    # Indices to words for each sentence (type: Int64Index([]))\n",
    "    sentence_index = sentID_group_obj.groups[sid]\n",
    "    sentence_df = malConll[malConll.index.isin(sentence_index)]\n",
    "    \n",
    "    nonce_sentence = []\n",
    "    \n",
    "    for index, row in sentence_df.iterrows():\n",
    "        \n",
    "        possible_replacements = word_index_to_df[index]\n",
    "        if possible_replacements.empty:\n",
    "            return get_new_nonce_sentence(sid)\n",
    "        random_idx = np.random.choice(possible_replacements.index, 1).tolist()[0]\n",
    "        nonce_sentence.append(random_idx)\n",
    "    \n",
    "    nonce_sent_index_str = ' '.join([str(ns) for ns in nonce_sentence])\n",
    "    if nonce_sent_index_str in traversed[sid]:\n",
    "        return get_new_nonce_sentence(sid)\n",
    "    else:\n",
    "        return nonce_sentence\n",
    "\n",
    "def get_incorrect_sentence(nonce_idx):\n",
    "    nonce_sentence_df = malConll[malConll.index.isin(nonce_idx)]   \n",
    "    \n",
    "for sid in sent_ids:\n",
    "    \n",
    "    if sid not in traversed:\n",
    "        traversed[sid] = {}\n",
    "    \n",
    "    if sid in skip_sent_ids:\n",
    "        continue\n",
    "    nonce_idx = get_new_nonce_sentence(sid)\n",
    "    print(\"{0} : {1}\".format(sid, nonce_idx))\n",
    "    get_incorrect_sentence(nonce_idx)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
